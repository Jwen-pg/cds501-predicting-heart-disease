---
title: "CDS505 Project"
output: pdf_document
---

# Loading Libraries

```{r}
library(caret)
library(corrplot)
library(e1071)
library(ggplot2)
library(knitr)
library(klaR)
library(randomForest)
library(rattle)
library(RColorBrewer)
library(rpart)
library(rpart.plot)
library(rsample)
library(varhandle)
```

# Setup knitr

```{r setup, include=FALSE, echo=FALSE}
# sets knitr working directory to the directory of this file
opts_knit$set(root.dir = dirname(rstudioapi::getActiveDocumentContext()$path))
```

# Loading Data

```{r}
# sets wroking directory to file's directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# reads dataset
data <- read.csv2("../data/cardio.csv")
```

# Preprocessing

```{r}
# drops 'id' attribute from the dataset
data <- subset(data, select = -c(id))

# recoding categorical or ordered data into readable format
data$cardio <- as.factor(ifelse(data$cardio == 0, "Negative", "Positive"))
data$active <- as.factor(ifelse(data$active == 0, "Inactive", "Active"))
data$alco <- as.factor(ifelse(data$alco == 0, "Non-alcoholic", "Alcoholic"))
data$smoke <- as.factor(ifelse(data$smoke == 0, "Non-smoker", "Smoker"))
data$gluc <- as.ordered(ifelse(data$gluc == 1, "Normal", ifelse(data$gluc == 2, "Above Normal", "Well Above Normal")))
data$cholesterol <- as.ordered(ifelse(data$cholesterol == 1, "Normal", ifelse(data$cholesterol == 2, "Above Normal", "Well Above Normal")))
data$gender <- as.factor(ifelse(data$gender == 1, "Woman", "Man"))

# converts 'weight' from character to numeric
data$weight <- unfactor(data$weight)

# converts unit of 'age' from days to years
data$age <- round(data$age / 365, digits = 0)

# creates 'BMI' column from corresponding 'height' and 'weight'
data$BMI <- (data$weight / ((data$height * 0.01) ^ 2))


# changes column names to readable format
colnames(data) <- c("Age", "Gender", "Height", "Weight", "Systole", "Diastole", "Cholesterol", "Glucose", "Smoking", "Alcohol", "Active", "Target", "BMI")

# change blood pressure into three levels: Low, Normal, High
data$BloodPressure = ifelse((data$Systole >= 140 | data$Diastole >= 90), "High", ifelse((data$Systole <= 90 | data$Diastole <= 60), "Low", "Normal"))
data$BloodPressure <- as.factor(data$BloodPressure)

head(data)
```

# Exploratory Analysis

## Summary Statistics

From the summary statistics, it is evident that the attributes 'Diastole' and 'Systole' have negative values, which are invalid. Also these two attributes, along with 'Weight' might have lots of outliers which need to be removed.

```{r}
# explores types of the attributes
unlist(sapply(data, class))

# summerizes dataset
summary(data)
```

## Age Distribution

```{r}
ggplot(data) + geom_density(aes(x = Age, fill = Target), alpha=0.8) + ggtitle("Age Density Plot") + xlab("Age") + ylab("Density") + theme_bw() + scale_fill_manual(values=c("#15158a", "#eb4034"))

# saves plot
png(file="../figures/age_dist.png", width=600, height=350)
ggplot(data) + geom_density(aes(x = Age, fill = Target), alpha=0.8) + ggtitle("Age Density Plot") + xlab("Age") + ylab("Density") + theme_bw() + scale_fill_manual(values=c("#15158a", "#eb4034"))
dev.off()
```

## Height Distribution

```{r}
ggplot(data) + geom_density(aes(x = Height, fill = Target), alpha=0.8) + ggtitle("Height Density Plot") + xlab("Height") + ylab("Density") + theme_bw() + scale_fill_manual(values=c("#15158a", "#eb4034"))

# saves plot
png(file="../figures/height_dist.png", width=600, height=350)
ggplot(data) + geom_density(aes(x = Height, fill = Target), alpha=0.8) + ggtitle("Height Density Plot") + xlab("Height") + ylab("Density") + theme_bw() + scale_fill_manual(values=c("#15158a", "#eb4034"))
dev.off()
```

## Weight Distribution

```{r}
ggplot(data) + geom_density(aes(x = Weight, fill = Target), alpha=0.8) + ggtitle("Weight Density Plot") + xlab("Weight") + ylab("Density") + theme_bw() + scale_fill_manual(values=c("#15158a", "#eb4034"))

# saves plot
png(file="../figures/weight_dist.png", width=600, height=350)
ggplot(data) + geom_density(aes(x = Weight, fill = Target), alpha=0.8) + ggtitle("Weight Density Plot") + xlab("Weight") + ylab("Density") + theme_bw() + scale_fill_manual(values=c("#15158a", "#eb4034"))
dev.off()
```

## BMI Distribution

```{r}
ggplot(data) + geom_density(aes(x = BMI, fill = Target), alpha=0.8) + ggtitle("BMI Density Plot") + xlab("BMI") + ylab("Density") + theme_bw() + scale_fill_manual(values=c("#15158a", "#eb4034"))

# saves plot
png(file="../figures/bmi_dist.png", width=600, height=350)
ggplot(data) + geom_density(aes(x = BMI, fill = Target), alpha=0.8) + ggtitle("BMI Density Plot") + xlab("BMI") + ylab("Density") + theme_bw() + scale_fill_manual(values=c("#15158a", "#eb4034"))
dev.off()
```

## Class Distribution

```{r}
ggplot(data) + geom_bar(aes(x = Target, fill = Target), alpha=0.8) + theme_bw() + ggtitle("Class Distribution") + xlab("Target") + ylab("Count") + scale_fill_manual(values=c("#15158a", "#eb4034"))

# saves plot
png(file="../figures/class_dist_outlier_removed.png", width=600, height=350)
ggplot(data) + geom_bar(aes(x = Target, fill = Target), alpha=0.8) + theme_bw() + ggtitle("Class Distribution") + xlab("Target") + ylab("Count") + scale_fill_manual(values=c("#15158a", "#eb4034"))
dev.off()
```

## Smoking Distribution

```{r}
ggplot(data) + geom_bar(aes(x = Smoking, fill = Target), position = 'dodge', alpha=0.8) + theme_bw() + ggtitle("Smoking Distribution") + xlab("Smoking") + ylab("Count") + scale_fill_manual(values=c("#15158a", "#eb4034"))

# saves plot
png(file="../figures/smoking_dist.png", width=600, height=350)
ggplot(data) + geom_bar(aes(x = Smoking, fill = Target), position = 'dodge', alpha=0.8) + theme_bw() + ggtitle("Smoking Distribution") + xlab("Smoking") + ylab("Count") + scale_fill_manual(values=c("#15158a", "#eb4034"))
dev.off()
```

## Alcohol Distribution

```{r}
ggplot(data) + geom_bar(aes(x = Alcohol, fill = Target), position = 'dodge', alpha=0.8) + theme_bw() + ggtitle("Alcohol Distribution") + xlab("Alcohol") + ylab("Count") + scale_fill_manual(values=c("#15158a", "#eb4034"))

# saves plot
png(file="../figures/alcohol_dist.png", width=600, height=350)
ggplot(data) + geom_bar(aes(x = Alcohol, fill = Target), position = 'dodge', alpha=0.8) + theme_bw() + ggtitle("Alcohol Distribution") + xlab("Alcohol") + ylab("Count") + scale_fill_manual(values=c("#15158a", "#eb4034"))
dev.off()
```

## Physical Activity Distribution

```{r}
ggplot(data) + geom_bar(aes(x = Active, fill = Target), position = 'dodge', alpha=0.8) + theme_bw() + ggtitle("Physical Activity Distribution") + xlab("Activity") + ylab("Count") + scale_fill_manual(values=c("#15158a", "#eb4034"))

# saves plot
png(file="../figures/activity_dist.png", width=600, height=350)
ggplot(data) + geom_bar(aes(x = Active, fill = Target), position = 'dodge', alpha=0.8) + theme_bw() + ggtitle("Physical Activity Distribution") + xlab("Activity") + ylab("Count") + scale_fill_manual(values=c("#15158a", "#eb4034"))
dev.off()
```

## Gender Distribution

```{r}
ggplot(data) + geom_bar(aes(x = Gender, fill = Target), position = 'dodge', alpha=0.8) + theme_bw() + ggtitle("Gender Distribution") + xlab("Gender") + ylab("Count") + scale_fill_manual(values=c("#15158a", "#eb4034"))

# saves plot
png(file="../figures/gender_dist.png", width=600, height=350)
ggplot(data) + geom_bar(aes(x = Gender, fill = Target), position = 'dodge', alpha=0.8) + theme_bw() + ggtitle("Gender Distribution") + xlab("Gender") + ylab("Count") + scale_fill_manual(values=c("#15158a", "#eb4034"))
dev.off()
```

## Cholesterol Distribution

```{r}
ggplot(data) + geom_bar(aes(x = Cholesterol, fill = Target), position = 'dodge', alpha=0.8) + theme_bw() + ggtitle(" Cholesterol Distribution") + xlab(" Cholesterol") + ylab("Count") + scale_fill_manual(values=c("#15158a", "#eb4034"))

# saves plot
png(file="../figures/cholesterol_dist.png", width=600, height=350)
ggplot(data) + geom_bar(aes(x = Cholesterol, fill = Target), position = 'dodge', alpha=0.8) + theme_bw() + ggtitle("Cholesterol Distribution") + xlab("Cholesterol") + ylab("Count") + scale_fill_manual(values=c("#15158a", "#eb4034"))
dev.off()
```

## Glucose Distribution

```{r}
ggplot(data) + geom_bar(aes(x = Glucose, fill = Target), position = 'dodge', alpha=0.8) + theme_bw() + ggtitle("Glucose Distribution") + xlab("Glucose") + ylab("Count") + scale_fill_manual(values=c("#15158a", "#eb4034"))

# saves plot
png(file="../figures/glucose_dist.png", width=600, height=350)
ggplot(data) + geom_bar(aes(x = Glucose, fill = Target), position = 'dodge', alpha=0.8) + theme_bw() + ggtitle("Glucose Distribution") + xlab("Glucose") + ylab("Count") + scale_fill_manual(values=c("#15158a", "#eb4034"))
dev.off()
```

## BloodPressure Distribution

```{r}
ggplot(data) + geom_bar(aes(x = BloodPressure, fill = Target), position = 'dodge', alpha=0.8) + theme_bw() + ggtitle("BloodPressure Distribution") + xlab("BloodPressure") + ylab("Count") + scale_fill_manual(values=c("#15158a", "#eb4034"))

# saves plot
png(file="../figures/BloodPressure_dist.png", width=600, height=350)
ggplot(data) + geom_bar(aes(x = BloodPressure, fill = Target), position = 'dodge', alpha=0.8) + theme_bw() + ggtitle("BloodPressure Distribution") + xlab("BloodPressure") + ylab("Count") + scale_fill_manual(values=c("#15158a", "#eb4034"))
dev.off()
```

# Managing Data

```{r}
# removes observation for which 'Systole' or 'Diastole' has negative values
data <- subset(data, Systole > 0 & Diastole > 0)

# removes 'ap_hi' and 'ap_lo' outliers
iqr_multiplier = 3
ap_hi_upper_threshold <- quantile(data$Systole, .75) + iqr_multiplier * (quantile(data$Systole, .75) - quantile(data$Systole, .25))
ap_hi_lower_threshold <- quantile(data$Systole, .25) - iqr_multiplier * (quantile(data$Systole, .75) - quantile(data$Systole, .25))
ap_lo_upper_threshold <- quantile(data$Diastole, .75) + iqr_multiplier * (quantile(data$Diastole, .75) - quantile(data$Diastole, .25))
ap_lo_lower_threshold <- quantile(data$Diastole, .25) - iqr_multiplier * (quantile(data$Diastole, .75) - quantile(data$Diastole, .25))
data <- subset(data, Systole < ap_hi_upper_threshold & Systole > ap_hi_lower_threshold & Diastole < ap_lo_upper_threshold & Diastole > ap_lo_lower_threshold)

# removes 'height' outliers'
height_iqr_multiplier = 1.5
height_upper_threshold <- quantile(data$Height, .75) + height_iqr_multiplier * (quantile(data$Height, .75) - quantile(data$Height, .25))
height_lower_threshold <- quantile(data$Height, .25) - height_iqr_multiplier * (quantile(data$Height, .75) - quantile(data$Height, .25))
data <- subset(data, Height > height_lower_threshold & Height < height_upper_threshold)

# removes 'weight' outliers'
weight_iqr_multiplier = 1.5
weight_upper_threshold <- quantile(data$Weight, .75) + weight_iqr_multiplier * (quantile(data$Weight, .75) - quantile(data$Weight, .25))
weight_lower_threshold <- quantile(data$Weight, .25) - weight_iqr_multiplier * (quantile(data$Weight, .75) - quantile(data$Weight, .25))
data <- subset(data, Weight > weight_lower_threshold & Weight < weight_upper_threshold)

data$Age = scale(data$Age)
data$Height = scale(data$Height)
data$Weight = scale(data$Weight)
data$BMI = scale(data$BMI)
data$Systole = scale(data$Systole)
data$Diastole = scale(data$Diastole)

# summerizes newly encoded dataset
summary(data)
```

# Feature Selection

## Boxplot of Age Attribute

```{r}
png(file="../figures/box_age.png", width=600, height=350)
p1 <- ggplot(data = data, aes(x=Target,y=Weight)) + 
           geom_point(aes(color=Weight), alpha=0.2) +
           geom_boxplot(outlier.size=4, outlier.colour='blue', alpha=0.1)
plot(p1)
dev.off()
```

## Boxplot of Weight Attribute

```{r}
png(file="../figures/box_weight.png", width=600, height=350)
p1 <- ggplot(data = data, aes(x=Target,y=Weight)) + 
           geom_point(aes(color=Weight), alpha=0.2) +
           geom_boxplot(outlier.size=4, outlier.colour='blue', alpha=0.1)
plot(p1)
dev.off()
```

## Boxplot of Height Attribute

```{r}
png(file="../figures/box_height.png", width=600, height=350)
p2 <- ggplot(data = data, aes(x=Target,y=Height)) + 
           geom_point(aes(color=Height), alpha=0.2) +
           geom_boxplot(outlier.size=4, outlier.colour='blue', alpha=0.1)
plot(p2)
dev.off()
```

## Boxplot of Systolic Blood Pressure

```{r}
png(file="../figures/box_systole.png", width=600, height=350)
p3 <- ggplot(data = data, aes(x=Target,y=Systole)) + 
           geom_point(aes(color=Systole), alpha=0.2) +
           geom_boxplot(outlier.size=4, outlier.colour='blue', alpha=0.1)
plot(p3)
dev.off()
```

## Boxplot of Diastolic Blood Pressure

```{r}
png(file="../figures/box_diastole.png", width=600, height=350)
p4 <- ggplot(data = data, aes(x=Target,y=Diastole)) + 
           geom_point(aes(color=Diastole), alpha=0.2) +
           geom_boxplot(outlier.size=4, outlier.colour='blue', alpha=0.1)
plot(p4)
dev.off()
```

## Boxplot of BMI

```{r}
png(file="../figures/box_bmi.png", width=600, height=350)
p5 <- ggplot(data = data, aes(x=Target,y=BMI)) + 
           geom_point(aes(color=BMI), alpha=0.2) +
           geom_boxplot(outlier.size=4, outlier.colour='blue', alpha=0.1)
plot(p5)
dev.off()
```

## Checking Near Zero Variance Attributes

Sometimes features may only have a single unique value. For many models, this may cause the model to crash or the fit to be unstable. Similarly, features may have only a few unique values that occur with very low frequencies. The concern here that these predictors may become zero-variance predictors when the data are split into cross-validation/bootstrap sub-samples or that a few samples may have an undue influence on the model. These “near-zero-variance” predictors may need to be identified and eliminated prior to modeling. However, no features had near zero variance.

```{r}
nzv <- nearZeroVar(data, saveMetrics= TRUE)
nzv
```

## Checking Strongly Correlated Features

Some models might show imporoved performance if the level of correlation between the predictors is reduced. Only BMI was found to have a strong correlation with Weight, which is obvious.

```{r}
numeric_features <- c("Age", "Height", "Weight", "Systole", "Diastole", "BMI")
# creates a correlation matrix
cr <- cor(data[, numeric_features])
cr
```

## Checking Linearly Dependent Features
No features were found to be linearly dependent among each other.

```{r}
ld <- findLinearCombos(data[, numeric_features])
ld
```

# Splitting Data

```{r}
# train/test split 
set.seed(1994)

# splits into train and test data
split <- initial_split(data, prop = 0.80, strata = "Target")
training_set <- training(split)
testing_set <- testing(split)

# checks class distribution after the split
cat("Training Set:")
prop.table(table(training_set$Target)) * 100
cat("Testing Set:")
prop.table(table(testing_set$Target)) * 100
```

# Modelling

## Single Variable Model
Single variable prediction using "Systole" attribute alone yields around 71.11% accuracy. This is the null model which our models have to beat. 

```{r}
tree_fit <- rpart(Target ~  ., data = training_set, control = rpart.control(maxdepth = 1), xval = 5)
tree_predictions <- predict(tree_fit, testing_set, type = "class")
confusionMatrix(as.factor(tree_predictions), testing_set[["Target"]], positive="Positive")
```


## Naive Bayes

### Recursive Feature Selection

```{r}
# subsets data for better performance
set.seed(19941021)
smpl_split <- initial_split(data, prop = 0.15, strata = "Target")
smpl_data <- training(smpl_split)

subsets <- c(5, 7, 13)
ctrl <- rfeControl(functions = nbFuncs, method = "cv", number = 5, verbose = FALSE)
rfProfile <- rfe(smpl_data[, which(colnames(smpl_data) != "Target")], smpl_data$Target, sizes = subsets, rfeControl = ctrl)

rfProfile
```

```{r}
print(predictors(rfProfile))
plot(rfProfile, type = c("g", "o"))
```

### Model

```{r}
nb_ctrl <- trainControl(method = "repeatedcv", number = 5, repeats=5, verbose = FALSE)
nb_model = naiveBayes(Target ~ Systole + BloodPressure + Diastole + Age + BMI + Weight + Cholesterol + Active, data = training_set, trControl = nb_ctrl)
```

## Logistic Regression

```{r}
lr_ctrl <- trainControl(method = "repeatedcv", number = 5, repeats=5, verbose = FALSE)
lr <- train(Target ~ Systole + BloodPressure + Diastole + Age + BMI + Weight + Cholesterol + Active, data = training_set, method = "LogitBoost", family = "binomial", trConrol = lr_ctrl)
```

## SVM

```{r}
svm_ctrl <- trainControl(method = "repeatedcv", number = 5, repeats=5,verbose = FALSE)
svm <- train(Target ~ Systole + BloodPressure + Diastole + Age + BMI + Weight + Cholesterol + Active, data = training_set, method = "svmLinear3", trConrol = lr_ctrl)
```

# Evaluation

## Naive Bayes

```{r}
nb_predictions <- predict(nb_model, testing_set)
confusionMatrix(as.factor(nb_predictions), testing_set[["Target"]], positive="Positive")
```

## Logistic Regression

```{r}
predictions <- predict(lr, testing_set)
confusionMatrix(as.factor(predictions), testing_set[["Target"]], positive="Positive")
```

## SVM

```{r}
svm_predictions <- predict(svm, testing_set)
confusionMatrix(as.factor(svm_predictions), testing_set[["Target"]], positive="Positive")
```
####################################END###########################################


















## Decision Tree

```{r}
tree_fit <- rpart(Target ~  Systole + Cholesterol + Age + Diastole + Weight, data = training_set, control = rpart.control(minsplit = 1000), xval = 5)
fancyRpartPlot(tree_fit)
tree_predictions <- predict(tree_fit, testing_set, type = "class")
confusionMatrix(as.factor(tree_predictions), testing_set[["Target"]], positive="Positive")
```

















```{r}
tree_fit2 <- rpart(Target ~  Age + BMI + Glucose + Active + BloodPressure, data = training_set, control = rpart.control(minsplit = 1000), xval = 5)
fancyRpartPlot(tree_fit2)
```
```{r}
tree_fit3 <- rpart(Target ~ ., data = training_set, control = rpart.control(minsplit = 1000), xval = 5)
fancyRpartPlot(tree_fit3)
```

```{r}
tree_fit4 <- rpart(Target ~ Age+Gender+Cholesterol+Glucose+Smoking+Alcohol+Active+BMI+BloodPressure, data = training_set, control = rpart.control(minsplit = 1000), xval = 5)
fancyRpartPlot(tree_fit4)
```

```{r}
#nb_model = naiveBayes(Target ~ ., data = training_set)
nb_model = naiveBayes(Target ~ Glucose + Smoking + Active + Alcohol, data = training_set)

nb_model2 = naiveBayes(Target ~ Age + BMI + Glucose + Active + BloodPressure, data = training_set)

nb_model3 = naiveBayes(Target ~ ., data = training_set)

nb_model4 = naiveBayes(Target ~Age+Gender+Cholesterol+Glucose+Smoking+Alcohol+Active+BMI+BloodPressure, data = training_set)
```

## Decision Tree

```{r}
predict <-  predict(tree_fit, testing_set, method = "class", type = "class")
dt_prediction <- table(Actual = testing_set$Target, Predicted = predict)
print(dt_prediction)

tree_precision <- posPredValue(as.factor(predict), testing_set[["Target"]], positive="Positive")
tree_recall <- sensitivity(predict, testing_set[["Target"]] , positive="Positive")
tree_accuracy <- sum(diag(dt_prediction))/sum(dt_prediction)

cat("\n")
cat("Decision Tree \n")
cat("Accuracy: ",tree_accuracy * 100, "%\n")
cat("Precision: ", tree_precision * 100 , "%\n")
cat("Recall: ", tree_recall * 100, "%\n")
cat("F1: ", (2 * tree_precision * tree_recall)/(tree_precision + tree_recall), "\n")
```

```{r}
predict2 <-  predict(tree_fit2, testing_set, method = "class", type = "class")
dt_prediction2 <- table(Actual = testing_set$Target, Predicted = predict2)
print(dt_prediction2)

tree_precision2 <- posPredValue(as.factor(predict2), testing_set[["Target"]], positive="Positive")
tree_recall2 <- sensitivity(predict2, testing_set[["Target"]] , positive="Positive")
tree_accuracy2 <- sum(diag(dt_prediction2))/sum(dt_prediction2)

cat("\n")
cat("Decision Tree\n")
cat("Accuracy: ",tree_accuracy2 * 100, "%\n")
cat("Precision: ", tree_precision2 * 100 , "%\n")
cat("Recall: ", tree_recall2 * 100, "%\n")
cat("F1: ", (2 * tree_precision2 * tree_recall2)/(tree_precision2 + tree_recall2), "\n")

```

```{r}
predict3 <-  predict(tree_fit3, testing_set, method = "class", type = "class")
dt_prediction3 <- table(Actual = testing_set$Target, Predicted = predict3)
print(dt_prediction3)

tree_precision3 <- posPredValue(as.factor(predict3), testing_set[["Target"]], positive="Positive")
tree_recall3 <- sensitivity(predict3, testing_set[["Target"]] , positive="Positive")
tree_accuracy3 <- sum(diag(dt_prediction3))/sum(dt_prediction3)

cat("\n")
cat("Decision Tree\n")
cat("Accuracy: ",tree_accuracy3 * 100, "%\n")
cat("Precision: ", tree_precision3 * 100 , "%\n")
cat("Recall: ", tree_recall3 * 100, "%\n")
cat("F1: ", (2 * tree_precision3 * tree_recall3)/(tree_precision3 + tree_recall3), "\n")

```

```{r}
predict4 <-  predict(tree_fit4, testing_set, method = "class", type = "class")
dt_prediction4 <- table(Actual = testing_set$Target, Predicted = predict4)
print(dt_prediction4)

tree_precision4 <- posPredValue(as.factor(predict4), testing_set[["Target"]], positive="Positive")
tree_recall4 <- sensitivity(predict4, testing_set[["Target"]] , positive="Positive")
tree_accuracy4 <- sum(diag(dt_prediction4))/sum(dt_prediction4)

cat("\n")
cat("Decision Tree\n")
cat("Accuracy: ",tree_accuracy4 * 100, "%\n")
cat("Precision: ", tree_precision4 * 100 , "%\n")
cat("Recall: ", tree_recall4 * 100, "%\n")
cat("F1: ", (2 * tree_precision4 * tree_recall4)/(tree_precision4 + tree_recall4), "\n")
```
```{r}
predicted_nb <-  predict(nb_model, testing_set, method = "class", type = "class")
nb_prediction <- table(Actual = testing_set$Target, Predicted = predicted_nb)
print(nb_prediction)

nb_precision <- posPredValue(as.factor(predicted_nb), testing_set[["Target"]], positive="Positive")
nb_recall <- sensitivity(predicted_nb, testing_set[["Target"]] , positive="Positive")
nb_accuracy <- sum(diag(nb_prediction))/sum(nb_prediction)
  
cat("\n")
cat("Naive Bayes\n")
cat("Accuracy: ",nb_accuracy * 100, "%\n")
cat("Precision: ", nb_precision * 100 , "%\n")
cat("Recall: ", nb_recall * 100, "%\n")
cat("F1: ", (2 * nb_precision * nb_recall)/(nb_precision + nb_recall), "\n")
```
```{r}
predicted_nb2 <-  predict(nb_model2, testing_set, method = "class", type = "class")
nb_prediction2 <- table(Actual = testing_set$Target, Predicted = predicted_nb2)
print(nb_prediction2)

nb_precision2 <- posPredValue(as.factor(predicted_nb2), testing_set[["Target"]], positive="Positive")
nb_recall2 <- sensitivity(predicted_nb2, testing_set[["Target"]] , positive="Positive")
nb_accuracy2 <- sum(diag(nb_prediction2))/sum(nb_prediction2)
  
cat("\n")
cat("Naive Bayes\n")
cat("Accuracy: ",nb_accuracy2 * 100, "%\n")
cat("Precision: ", nb_precision2 * 100 , "%\n")
cat("Recall: ", nb_recall2 * 100, "%\n")
cat("F1: ", (2 * nb_precision2 * nb_recall2)/(nb_precision2 + nb_recall2), "\n")
```
```{r}
predicted_nb3 <-  predict(nb_model3, testing_set, method = "class", type = "class")
nb_prediction3 <- table(Actual = testing_set$Target, Predicted = predicted_nb3)
print(nb_prediction3)

nb_precision3 <- posPredValue(as.factor(predicted_nb3), testing_set[["Target"]], positive="Positive")
nb_recall3 <- sensitivity(predicted_nb3, testing_set[["Target"]] , positive="Positive")
nb_accuracy3 <- sum(diag(nb_prediction3))/sum(nb_prediction3)
  
cat("\n")
cat("Naive Bayes\n")
cat("Accuracy: ",nb_accuracy3 * 100, "%\n")
cat("Precision: ", nb_precision3 * 100 , "%\n")
cat("Recall: ", nb_recall3 * 100, "%\n")
cat("F1: ", (2 * nb_precision3 * nb_recall3)/(nb_precision3 + nb_recall3), "\n")
```

```{r}
predicted_nb4 <-  predict(nb_model4, testing_set, method = "class", type = "class")
nb_prediction4 <- table(Actual = testing_set$Target, Predicted = predicted_nb4)
print(nb_prediction4)

nb_precision4 <- posPredValue(as.factor(predicted_nb4), testing_set[["Target"]], positive="Positive")
nb_recall4 <- sensitivity(predicted_nb4, testing_set[["Target"]] , positive="Positive")
nb_accuracy4 <- sum(diag(nb_prediction4))/sum(nb_prediction4)
  
cat("\n")
cat("Naive Bayes\n")
cat("Accuracy: ",nb_accuracy4 * 100, "%\n")
cat("Precision: ", nb_precision4 * 100 , "%\n")
cat("Recall: ", nb_recall4 * 100, "%\n")
cat("F1: ", (2 * nb_precision4 * nb_recall4)/(nb_precision4 + nb_recall4), "\n")
```






